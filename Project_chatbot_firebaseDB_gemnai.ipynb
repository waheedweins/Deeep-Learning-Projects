{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7J8gAP8tYgQ1Exx6GYOmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waheedweins/Langchain_projects/blob/main/Project_chatbot_firebaseDB_gemnai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydotenv google-cloud-firestore langchain-google-firestore langchain-openai -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn1Ogk0HIQJ5",
        "outputId": "5caf28a9-5c6f-4538-b7d0-d57889fe3b07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.1/420.1 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pydotenv (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai -qU\n",
        "!pip install update langchain_google_genai -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja58kocwI4Qg",
        "outputId": "7ffd246b-944c-4c93-b69c-299662688a52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI"
      ],
      "metadata": {
        "id": "zu34wfOkmfWQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVqF_hR7Ixx9",
        "outputId": "cee40c32-bffa-4f85-da7a-e93afc5bc006"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import firestore\n",
        "from langchain_google_firestore import FirestoreChatMessageHistory\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set up Firestore authentication using uploaded JSON file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/langchain-4aaf9-firebase-adminsdk-fbsvc-99b21ebba3.json'  # Use uploaded key\n",
        "\n",
        "# Initialize Firestore Client\n",
        "PROJECT_ID = \"langchain-4aaf9\"  # Change this to your actual project ID\n",
        "SESSION_ID = \"user_session_new\"\n",
        "COLLECTION_NAME = \"chat_history\"\n",
        "\n",
        "print(\"Initializing Firestore Client...\")\n",
        "client = firestore.Client(project=PROJECT_ID)\n",
        "\n",
        "# Initialize Firestore Chat Message History\n",
        "print(\"Initializing Firestore Chat Message History...\")\n",
        "chat_history = FirestoreChatMessageHistory(\n",
        "    session_id=SESSION_ID,\n",
        "    collection=COLLECTION_NAME,\n",
        "    client=client,\n",
        ")\n",
        "print(\"Chat History Initialized.\")\n",
        "print(\"Current Chat History:\", chat_history.messages)\n",
        "\n",
        "# Initialize OpenAI Chat Model\n",
        "model = GoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
        "\n",
        "# Chat Interaction\n",
        "print(\"Start chatting with the AI. Type 'exit' to quit.\")\n",
        "\n",
        "while True:\n",
        "    human_input = input(\"User: \")\n",
        "    if human_input.lower() == \"exit\":\n",
        "        print(\"Exiting chat...\")\n",
        "        break\n",
        "\n",
        "    chat_history.add_user_message(human_input)\n",
        "\n",
        "    ai_response = model.invoke(chat_history.messages)\n",
        "    chat_history.add_ai_message(ai_response)\n",
        "\n",
        "    print(f\"AI: {ai_response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm4g8z5FKnBp",
        "outputId": "b922665e-5096-4826-f982-731ebf0339bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Firestore Client...\n",
            "Initializing Firestore Chat Message History...\n",
            "Chat History Initialized.\n",
            "Current Chat History: [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]\n",
            "Start chatting with the AI. Type 'exit' to quit.\n",
            "User: hi\n",
            "AI: Human: hi\n",
            "User: how are you\n",
            "AI: AI: I'm doing well, thank you for asking. How are you?\n",
            "User: I love you\n",
            "AI: AI: That's very kind of you to say. As an AI, I don't experience emotions in the same way humans do, so I can't reciprocate romantic love. However, I appreciate your kind words and I'm here to help you with anything you need.  Is there anything I can assist you with today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV8NOKtq76H1"
      },
      "outputs": [],
      "source": []
    }
  ]
}